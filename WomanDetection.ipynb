{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6742ce-0a8f-418e-a8e6-f0ec3361d243",
   "metadata": {},
   "source": [
    "**Github repo used for the following purposes**: [link](https://github.com/WyattAutomation/Train-YOLOv3-with-OpenImagesV4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4f5da5-8676-4484-83cc-c82cd995e99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'OIDv4_ToolKit' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/EscVM/OIDv4_ToolKit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15352133-31af-4e7d-817d-88f8e32a4b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from -r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: numpy in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from -r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: awscli in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from -r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 3)) (1.43.2)\n",
      "Requirement already satisfied: urllib3 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from -r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: tqdm in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from -r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 7)) (4.66.5)\n",
      "Requirement already satisfied: opencv-python in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from -r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 9)) (4.12.0.88)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pandas->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 1)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pandas->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from pandas->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: botocore==1.41.2 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from awscli->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 3)) (1.41.2)\n",
      "Requirement already satisfied: docutils<=0.19,>=0.18.1 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from awscli->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 3)) (0.19)\n",
      "Requirement already satisfied: s3transfer<0.16.0,>=0.15.0 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from awscli->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 3)) (0.15.0)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from awscli->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from awscli->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from awscli->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 3)) (4.7.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from botocore==1.41.2->awscli->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from rsa<4.8,>=3.1.2->awscli->-r /home/khaled-ekramy/OIDv4_ToolKit/requirements.txt (line 3)) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r \"/home/khaled-ekramy/OIDv4_ToolKit/requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ef2e3-16d5-4f85-b8b7-3f6a027d3869",
   "metadata": {},
   "source": [
    "**Ensuring that kernel is using GPU to process the model and the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c39f80f7-42cc-4087-b7b4-2d6bc22f96d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available() #Value should be True if kernel is using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a83edbb-adf9-4d91-a430-bb6cfaed4344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 23 07:28:54 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro T1000                   Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P8              1W /   50W |       8MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3309      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi #GPU information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2a457-974e-4b70-86c7-c6f625948bd5",
   "metadata": {},
   "source": [
    "## Our main plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5166650-6325-4a53-b94b-c14db725d2a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Final Plan Summary:\n",
    "\n",
    "**Model**: YOLOv8n  \n",
    "**Dataset**: ALL Woman class images from OpenImages V7 (~40K-60K images)  \n",
    "**Resolution**: 416x416 (45-50 FPS target)  \n",
    "**Classes**: Woman only (class 0)  \n",
    "**Training**: Google Colab Pro  \n",
    "**Deployment**: Nvidia T1000 4GB\n",
    "**Goal**: Very low false positive rate  \n",
    "\n",
    "### Implementation Steps We'll Build:\n",
    "\n",
    "1. **Data Preparation**:\n",
    "   - Download only Woman class images from OpenImages V7 using OID toolkit\n",
    "   - Convert annotations to YOLO format\n",
    "   - Train/val/test split (80/15/5)\n",
    "\n",
    "2. **Training Pipeline**:\n",
    "   - Load YOLOv8n pretrained on COCO\n",
    "   - Fine-tune on Woman class\n",
    "   - Strong augmentation to reduce false positives\n",
    "   - Train for sufficient epochs (~50-100)\n",
    "\n",
    "3. **Optimization**:\n",
    "   - Export to TensorRT FP16\n",
    "   - Optimize for T1000 inference\n",
    "\n",
    "4. **Validation**:\n",
    "   - Test precision/recall\n",
    "   - Measure FPS on T1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a9dbd-66a7-4ba6-a82e-6c6f59b87afb",
   "metadata": {},
   "source": [
    "## Downloading Woman Class dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662bf5c0-a56e-47b2-8a72-9ba719e5adff",
   "metadata": {},
   "source": [
    "### Step1: Importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dce02f6-a3fe-48c1-ac74-7e2aeb9c4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa1d77-9038-4cec-965c-1240c977787d",
   "metadata": {},
   "source": [
    "### Step2: Creating directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6021fe04-7c49-402f-a55c-b1496c828a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OpenImages V7 - Woman Class Download\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"./openimages_woman\"  # Local directory\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "os.chdir(base_dir) #changing the working directory of the python session to this folder\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OpenImages V7 - Woman Class Download\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a14070-f838-4f79-9cc5-faf25ad5ee93",
   "metadata": {},
   "source": [
    "### Step3: Download Woman class images\n",
    "- Class name in OpenImages: \"Woman\"\n",
    "- This will download train, validation, and test sets\n",
    "\n",
    "**Terminal code if we don't wanna do it inside the notebook**\n",
    "- Just make sure the notebook you have OID toolkit files inside your working director.\n",
    "- In summary the notebook should be in the same directory with `main.py` file.\n",
    "```bash\n",
    "python main.py downloader --classes Woman --type_csv train --limit 50000\n",
    "python main.py downloader --classes Woman --type_csv validation --limit 5000\n",
    "python main.py downloader --classes Woman --type_csv test --limit 2000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341bdead-c1f2-435a-8d6d-bb87c29fe0e4",
   "metadata": {},
   "source": [
    "#### Downloading Train Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b0381-03c7-4f93-ad4b-ec6bf588c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Downloading TRAIN images with Woman class...\")\n",
    "try:\n",
    "    subprocess.run([\n",
    "        sys.executable, \"OIDv4_ToolKit/main.py\",\n",
    "        \"downloader\",\n",
    "        \"--classes\", \"Woman\",\n",
    "        \"--type_csv\", \"train\",\n",
    "        \"--limit\", \"50000\",\n",
    "        \"--multiclasses\", \"0\",\n",
    "        \"--yes\"\n",
    "    ], check=True)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\" Error during download:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1020d72-f7ee-4659-8325-321abf69bf89",
   "metadata": {},
   "source": [
    "#### Downloading Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544f590-a943-422e-927a-0cd66718752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Downloading VALIDATION images with Woman class...\")\n",
    "try:\n",
    "    subprocess.run([\n",
    "        sys.executable, \"OIDv4_ToolKit/main.py\",\n",
    "        \"downloader\",\n",
    "        \"--classes\", \"Woman\",\n",
    "        \"--type_csv\", \"validation\",\n",
    "        \"--limit\", \"5000\",\n",
    "        \"--multiclasses\", \"0\",\n",
    "        \"--yes\"\n",
    "    ], check=True)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\" Error during validation download (return code {e.returncode}): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54178c20-ca76-4793-9134-dc576ded4aa9",
   "metadata": {},
   "source": [
    "#### Downloading Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7708a-e8eb-4bc5-8b91-6ed57894f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Downloading TEST images with Woman class...\")\n",
    "try:\n",
    "    subprocess.run([\n",
    "        sys.executable, \"OIDv4_ToolKit/main.py\",\n",
    "        \"downloader\",\n",
    "        \"--classes\", \"Woman\",\n",
    "        \"--type_csv\", \"test\",\n",
    "        \"--limit\", \"2000\",\n",
    "        \"--multiclasses\", \"0\",\n",
    "        \"--yes\"\n",
    "    ], check=True)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\" Error during validation download (return code {e.returncode}): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a05ef4-fd09-4cb1-a758-512658632bf0",
   "metadata": {},
   "source": [
    "### Checking Download Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f44dc69-45a6-4be5-8926-de675f215a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DOWNLOAD SUMMARY\n",
      "\n",
      "============================================================\n",
      "TRAIN: 49928 images, 49928 labels\n",
      "VALIDATION: 1936 images, 1936 labels\n",
      "TEST: 1998 images, 1998 labels\n",
      "\n",
      " Dataset location: ./openimages_woman/OID/Dataset/\n",
      " Download complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DOWNLOAD SUMMARY\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    split_path = Path(f\"OID/Dataset/{split}/Woman\")\n",
    "    if split_path.exists():\n",
    "        img_count = len(list(split_path.glob(\"*.jpg\")))\n",
    "        label_count = len(list(split_path.glob(\"Label/*.txt\")))\n",
    "        print(f\"{split.upper()}: {img_count} images, {label_count} labels\")\n",
    "    else:\n",
    "        print(f\"{split.upper()}: Not found\")\n",
    "\n",
    "print(\"\\n Dataset location: ./openimages_woman/OID/Dataset/\")\n",
    "print(\" Download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ada1d-946a-4ea2-883c-9dbbd977e805",
   "metadata": {},
   "source": [
    "### Step 4: Display dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30085a31-69fd-40fc-bbc7-51559c48f2c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ“‚ DIRECTORY STRUCTURE\n",
      "============================================================\n",
      "\n",
      "train/\n",
      "  â””â”€â”€ Woman/\n",
      "    â””â”€â”€ Label/\n",
      "        â””â”€â”€ 49928 txt files\n",
      "    Images Count = 49928 Images\n",
      "\n",
      "validation/\n",
      "  â””â”€â”€ Woman/\n",
      "    â””â”€â”€ Label/\n",
      "        â””â”€â”€ 1936 txt files\n",
      "    Images Count = 1936 Images\n",
      "\n",
      "test/\n",
      "  â””â”€â”€ Woman/\n",
      "    â””â”€â”€ Label/\n",
      "        â””â”€â”€ 1998 txt files\n",
      "    Images Count = 1998 Images\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“‚ DIRECTORY STRUCTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    split_path = Path(f\"OID/Dataset/{split}\")\n",
    "    if split_path.exists():\n",
    "        print(f\"\\n{split}/\")\n",
    "        \n",
    "        for item in split_path.iterdir():\n",
    "            print(f\"  â””â”€â”€ {item.name}/\")\n",
    "\n",
    "        for p in item.iterdir():\n",
    "            if p.is_dir():\n",
    "                print(f\"    â””â”€â”€ {p.name}/\")\n",
    "                print(f\"        â””â”€â”€ {len(list(p.glob('*.txt')))} txt files\")\n",
    "        \n",
    "        jpg_count = len(list(item.glob(\"*.jpg\")))\n",
    "        print(f\"    Images Count = {jpg_count} Images\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30821cf-6675-4273-94af-fe77b140ef08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graduation-Project-env",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
